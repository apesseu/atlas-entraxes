"""
Configuration et constantes pour Atlas Entraxes.

Ce module centralise tous les param√®tres de configuration, chemins de fichiers,
et constantes utilis√©es dans l'application Atlas Entraxes. Il fournit √©galement
les fonctions de validation pour s'assurer que tous les fichiers requis sont
pr√©sents avant le d√©marrage de l'application.

Auteur: apesseu
Version: 0.1.0
"""

from pathlib import Path
from typing import List, Optional, Tuple
import logging
import sys

# Configuration du logging pour ce module
logger = logging.getLogger(__name__)

# ====== CHEMINS DE FICHIERS ======

# R√©pertoire racine des donn√©es
DATA_DIR: Path = Path(__file__).parent / "data"
"""R√©pertoire contenant tous les fichiers de donn√©es de l'application."""

# Fichiers de donn√©es principaux
GEOJSON_PATH: Path = DATA_DIR / "departements.geojson"
"""Fichier GeoJSON contenant les contours g√©ographiques des d√©partements fran√ßais."""

ZONES_PATH: Path = DATA_DIR / "dept_zones_NORMALISE.csv"
"""Fichier CSV contenant l'association d√©partement -> zones vent/neige."""

RULES_PATH: Path = DATA_DIR / "results_by_combo.csv"
"""Fichier CSV contenant les r√®gles de calcul (c≈ìur m√©tier de l'application)."""

DETAILS_PATH: Path = DATA_DIR / "details.csv"
"""Fichier CSV contenant les m√©tadonn√©es descriptives des configurations."""

# Fichiers optionnels
EXCEL_ZONES_PATH: Path = DATA_DIR / "dept_zones.xlsx"
"""Fichier Excel source des zones (optionnel, pour r√©f√©rence)."""

# ====== PARAM√àTRES APPLICATION ======

APP_TITLE: str = "Atlas Entraxes 2025"
"""Titre principal de l'application Dash."""

APP_DESCRIPTION: str = "Visualisation moderne des altitudes maximales par d√©partement"
"""Description affich√©e sous le titre principal."""

DEBUG_MODE: bool = True
"""Active le mode debug de l'application Dash."""

HOST: str = "127.0.0.1"
"""Adresse IP d'√©coute du serveur Dash."""

PORT: int = 8050
"""Port d'√©coute du serveur Dash."""

# ====== PARAM√àTRES TECHNIQUES ======

DEFAULT_ENCODING: str = "utf-8"
"""Encodage par d√©faut pour la lecture des fichiers texte."""

MAX_FILE_SIZE_MB: int = 100
"""Taille maximale autoris√©e pour les fichiers de donn√©es (en MB)."""

# Types de donn√©es pandas pour garantir la coh√©rence
ZONES_DTYPES: dict = {
    "Dept": "string",
    "Nom": "string", 
    "Zone_Vent": "string",
    "Zone_Neige": "string"
}
"""Types de donn√©es pour le fichier des zones d√©partementales."""

RULES_DTYPES: dict = {
    "Config": "string",
    "Zone_Vent": "string",
    "Zone_Neige": "string",
    "AltMax_3m": "string",
    "AltMax_2_5m": "string"
}
"""Types de donn√©es pour le fichier des r√®gles de calcul."""

DETAILS_DTYPES: dict = {
    "Config": "string",
    "Type_Serre": "string",
    "Hauteur_Poteau": "string",
    "Largeur": "string",
    "Toiture": "string",
    "Facade": "string",
    "Traverse": "string",
    "Materiau": "string",
    "Resistance_Vent": "string",
    "Date_Creation": "string",
    "Version": "string"
}
"""Types de donn√©es pour le fichier des d√©tails de configuration."""

# ====== FONCTIONS DE VALIDATION ======

def validate_file_existence(file_path: Path, file_description: str = "") -> bool:
    """
    Valide qu'un fichier existe et est accessible en lecture.
    
    Args:
        file_path (Path): Chemin vers le fichier √† valider.
        file_description (str, optional): Description du fichier pour les messages d'erreur.
    
    Returns:
        bool: True si le fichier existe et est accessible.
        
    Raises:
        FileNotFoundError: Si le fichier n'existe pas.
        PermissionError: Si le fichier n'est pas accessible en lecture.
    """
    description = file_description or f"'{file_path.name}'"
    
    if not file_path.exists():
        error_msg = f"Le fichier {description} est introuvable : {file_path.absolute()}"
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    if not file_path.is_file():
        error_msg = f"Le chemin {description} n'est pas un fichier : {file_path.absolute()}"
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    # V√©rifier les permissions de lecture
    try:
        with open(file_path, 'r', encoding=DEFAULT_ENCODING) as f:
            f.read(1)  # Lire juste 1 caract√®re pour tester l'acc√®s
    except PermissionError as e:
        error_msg = f"Impossible de lire le fichier {description} : {e}"
        logger.error(error_msg)
        raise PermissionError(error_msg)
    except UnicodeDecodeError:
        # Fichier binaire, on teste juste l'ouverture en mode binaire
        try:
            with open(file_path, 'rb') as f:
                f.read(1)
        except PermissionError as e:
            error_msg = f"Impossible de lire le fichier {description} : {e}"
            logger.error(error_msg)
            raise PermissionError(error_msg)
    
    logger.info(f"Fichier {description} valid√© avec succ√®s : {file_path}")
    return True


def validate_file_size(file_path: Path, max_size_mb: int = MAX_FILE_SIZE_MB) -> bool:
    """
    Valide que la taille d'un fichier ne d√©passe pas la limite autoris√©e.
    
    Args:
        file_path (Path): Chemin vers le fichier √† valider.
        max_size_mb (int, optional): Taille maximale en MB.
        
    Returns:
        bool: True si la taille est acceptable.
        
    Raises:
        ValueError: Si le fichier est trop volumineux.
    """
    file_size_bytes = file_path.stat().st_size
    file_size_mb = file_size_bytes / (1024 * 1024)
    
    if file_size_mb > max_size_mb:
        error_msg = (
            f"Le fichier '{file_path.name}' est trop volumineux "
            f"({file_size_mb:.1f} MB > {max_size_mb} MB)"
        )
        logger.error(error_msg)
        raise ValueError(error_msg)
    
    logger.info(f"Taille du fichier '{file_path.name}' valid√©e : {file_size_mb:.1f} MB")
    return True


def check_required_files(include_optional: bool = False) -> List[Path]:
    """
    V√©rifie que tous les fichiers requis pour l'application sont pr√©sents et accessibles.
    
    Args:
        include_optional (bool, optional): Si True, inclut aussi les fichiers optionnels.
    
    Returns:
        List[Path]: Liste des fichiers valid√©s avec succ√®s.
        
    Raises:
        FileNotFoundError: Si un ou plusieurs fichiers requis sont manquants.
    """
    logger.info("D√©marrage de la validation des fichiers requis...")
    
    # Fichiers obligatoires avec leurs descriptions
    required_files: List[Tuple[Path, str]] = [
        (GEOJSON_PATH, "donn√©es g√©ographiques des d√©partements"),
        (ZONES_PATH, "zones r√©glementaires par d√©partement"), 
        (RULES_PATH, "r√®gles de calcul principales")
    ]
    
    # Fichiers optionnels
    optional_files: List[Tuple[Path, str]] = [
        (DETAILS_PATH, "d√©tails des configurations"),
        (EXCEL_ZONES_PATH, "fichier Excel des zones (source)")
    ]
    
    validated_files: List[Path] = []
    validation_errors: List[str] = []
    
    # Validation des fichiers requis
    for file_path, description in required_files:
        try:
            validate_file_existence(file_path, description)
            validate_file_size(file_path)
            validated_files.append(file_path)
            logger.info(f"‚úì {description} : OK")
            
        except (FileNotFoundError, PermissionError, ValueError) as e:
            validation_errors.append(str(e))
            logger.error(f"‚úó {description} : ERREUR - {e}")
    
    # Validation des fichiers optionnels si demand√©
    if include_optional:
        for file_path, description in optional_files:
            try:
                if file_path.exists():
                    validate_file_existence(file_path, description)
                    validate_file_size(file_path)
                    validated_files.append(file_path)
                    logger.info(f"‚úì {description} (optionnel) : OK")
                else:
                    logger.info(f"‚óã {description} (optionnel) : absent (pas d'erreur)")
                    
            except (PermissionError, ValueError) as e:
                # Pour les fichiers optionnels, on log l'erreur mais on n'arr√™te pas
                logger.warning(f"! {description} (optionnel) : ATTENTION - {e}")
    
    # Si des erreurs sur fichiers requis, on arr√™te tout
    if validation_errors:
        error_summary = (
            f"Validation √©chou√©e. {len(validation_errors)} erreur(s) d√©tect√©e(s) :\n" +
            "\n".join(f"  ‚Ä¢ {error}" for error in validation_errors)
        )
        logger.critical(error_summary)
        raise FileNotFoundError(error_summary)
    
    logger.info(f"‚úÖ Validation r√©ussie ! {len(validated_files)} fichier(s) valid√©(s).")
    return validated_files


def validate_data_consistency() -> bool:
    """
    Valide la coh√©rence entre les diff√©rents fichiers de donn√©es.
    
    Returns:
        bool: True si tous les fichiers sont coh√©rents.
        
    Raises:
        ValueError: En cas d'incoh√©rence d√©tect√©e.
    """
    try:
        import pandas as pd
    except ImportError:
        logger.warning("Pandas non disponible, validation de coh√©rence ignor√©e")
        return True
    
    logger.info("Validation de la coh√©rence des donn√©es...")
    
    try:
        # Chargement des donn√©es
        zones_df = pd.read_csv(ZONES_PATH, dtype=ZONES_DTYPES)
        rules_df = pd.read_csv(RULES_PATH, dtype=RULES_DTYPES)
        
        # Validation optionnelle du fichier details
        if DETAILS_PATH.exists():
            details_df = pd.read_csv(DETAILS_PATH, dtype=DETAILS_DTYPES)
            
            # V√©rifier que toutes les configs dans details existent dans rules
            configs_details = set(details_df['Config'].dropna().unique())
            configs_rules = set(rules_df['Config'].dropna().unique())
            
            missing_configs = configs_details - configs_rules
            if missing_configs:
                raise ValueError(
                    f"Configurations dans details.csv absentes de results_by_combo.csv: "
                    f"{', '.join(missing_configs)}"
                )
            
            logger.info(f"‚úì Coh√©rence details.csv ‚Üî results_by_combo.csv : {len(configs_details)} configurations")
        
        # V√©rifier que toutes les zones dans rules existent dans zones
        zones_in_rules = set()
        zones_in_rules.update(rules_df['Zone_Vent'].dropna().unique())
        zones_in_rules.update(rules_df['Zone_Neige'].dropna().unique())
        
        zones_available = set()
        zones_available.update(zones_df['Zone_Vent'].dropna().unique())
        zones_available.update(zones_df['Zone_Neige'].dropna().unique())
        
        missing_zones = zones_in_rules - zones_available
        if missing_zones:
            raise ValueError(
                f"Zones dans results_by_combo.csv absentes de dept_zones_NORMALISE.csv: "
                f"{', '.join(missing_zones)}"
            )
        
        logger.info(f"‚úì Coh√©rence results_by_combo.csv ‚Üî dept_zones_NORMALISE.csv : {len(zones_in_rules)} zones")
        logger.info("‚úÖ Validation de coh√©rence r√©ussie !")
        return True
        
    except Exception as e:
        error_msg = f"Erreur lors de la validation de coh√©rence : {e}"
        logger.error(error_msg)
        raise ValueError(error_msg)


def get_data_dir_info() -> dict:
    """
    Retourne des informations sur le r√©pertoire de donn√©es.
    
    Returns:
        dict: Informations sur le r√©pertoire (existence, permissions, contenu, etc.)
    """
    info = {
        "path": str(DATA_DIR.absolute()),
        "exists": DATA_DIR.exists(),
        "is_directory": DATA_DIR.is_dir() if DATA_DIR.exists() else False,
        "file_count": 0,
        "files": [],
        "readable": False
    }
    
    if info["exists"] and info["is_directory"]:
        try:
            files = list(DATA_DIR.iterdir())
            info["file_count"] = len([f for f in files if f.is_file()])
            info["files"] = [f.name for f in files if f.is_file()]
            info["readable"] = True
        except PermissionError:
            logger.warning(f"Impossible de lister le contenu de {DATA_DIR}")
    
    return info


def get_config_details(config_name: str) -> Optional[dict]:
    """
    R√©cup√®re les d√©tails d'une configuration sp√©cifique.
    
    Args:
        config_name (str): Nom de la configuration (ex: "holyspirit4")
    
    Returns:
        Optional[dict]: Dictionnaire avec les d√©tails de la configuration,
                       ou None si la configuration n'existe pas.
    """
    if not DETAILS_PATH.exists():
        logger.info(f"Fichier {DETAILS_PATH} non trouv√©, d√©tails non disponibles")
        return None
    
    try:
        import pandas as pd
        details_df = pd.read_csv(DETAILS_PATH, dtype=DETAILS_DTYPES)
        
        # Recherche de la configuration
        config_row = details_df[details_df['Config'] == config_name]
        
        if config_row.empty:
            logger.info(f"Configuration '{config_name}' non trouv√©e dans details.csv")
            return None
        
        # Conversion en dictionnaire (premi√®re ligne si plusieurs)
        details_dict = config_row.iloc[0].to_dict()
        
        # Nettoyage des valeurs NaN
        details_clean = {
            key: value for key, value in details_dict.items() 
            if pd.notna(value) and str(value).strip()
        }
        
        logger.info(f"D√©tails trouv√©s pour la configuration '{config_name}'")
        return details_clean
        
    except Exception as e:
        logger.error(f"Erreur lors de la lecture des d√©tails pour '{config_name}': {e}")
        return None


def list_available_configs() -> List[str]:
    """
    Retourne la liste de toutes les configurations disponibles.
    
    Returns:
        List[str]: Liste tri√©e des noms de configurations disponibles.
    """
    configs = set()
    
    try:
        import pandas as pd
        
        # Configurations depuis rules.csv (fichier principal)
        if RULES_PATH.exists():
            rules_df = pd.read_csv(RULES_PATH, dtype=RULES_DTYPES)
            configs.update(rules_df['Config'].dropna().unique())
        
        # Configurations depuis details.csv (m√©tadonn√©es)
        if DETAILS_PATH.exists():
            details_df = pd.read_csv(DETAILS_PATH, dtype=DETAILS_DTYPES)
            configs.update(details_df['Config'].dropna().unique())
        
        sorted_configs = sorted(list(configs))
        logger.info(f"Configurations disponibles : {len(sorted_configs)}")
        return sorted_configs
        
    except Exception as e:
        logger.error(f"Erreur lors de la lecture des configurations : {e}")
        return []


def setup_logging(level: str = "INFO") -> None:
    """
    Configure le syst√®me de logging pour l'application.
    
    Args:
        level (str, optional): Niveau de log (DEBUG, INFO, WARNING, ERROR, CRITICAL).
    """
    numeric_level = getattr(logging, level.upper(), logging.INFO)
    
    logging.basicConfig(
        level=numeric_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    logger.info(f"Logging configur√© au niveau {level}")


# ====== INITIALISATION DU MODULE ======

# Configuration automatique du logging lors de l'import
if __name__ != "__main__":
    setup_logging("INFO" if not DEBUG_MODE else "DEBUG")


# ====== POINT D'ENTR√âE POUR TESTS ======

if __name__ == "__main__":
    """
    Point d'entr√©e pour tester le module de configuration.
    
    Usage:
        python config.py
    """
    print("=== Test du module de configuration Atlas Entraxes ===")
    
    # Configuration du logging pour les tests
    setup_logging("DEBUG")
    
    try:
        # Affichage des informations de base
        print(f"\nüìÅ R√©pertoire de donn√©es : {DATA_DIR.absolute()}")
        data_info = get_data_dir_info()
        print(f"   Existe : {data_info['exists']}")
        print(f"   Fichiers : {data_info['file_count']}")
        if data_info['files']:
            print("   Contenu :", ", ".join(data_info['files']))
        
        print(f"\nüîß Configuration application :")
        print(f"   Titre : {APP_TITLE}")
        print(f"   Debug : {DEBUG_MODE}")
        print(f"   Serveur : {HOST}:{PORT}")
        
        # Test de validation des fichiers
        print(f"\nüîç Validation des fichiers requis...")
        validated_files = check_required_files(include_optional=True)
        print(f"‚úÖ {len(validated_files)} fichier(s) valid√©(s) avec succ√®s !")
        
        # Test de coh√©rence des donn√©es
        print(f"\nüîó Validation de la coh√©rence des donn√©es...")
        try:
            validate_data_consistency()
            print("‚úÖ Coh√©rence des donn√©es valid√©e !")
        except Exception as e:
            print(f"‚ö†Ô∏è  Validation de coh√©rence √©chou√©e : {e}")
        
        # Test des fonctions utilitaires
        print(f"\nüìã Test des fonctions utilitaires...")
        configs = list_available_configs()
        print(f"   Configurations trouv√©es : {len(configs)}")
        if configs:
            print(f"   Exemples : {', '.join(configs[:3])}")
            
            # Test de r√©cup√©ration des d√©tails pour la premi√®re config
            if configs:
                details = get_config_details(configs[0])
                if details:
                    print(f"   D√©tails pour '{configs[0]}' : {len(details)} champs")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test : {e}")
        sys.exit(1)
    
    print(f"\n‚ú® Module de configuration pr√™t √† √™tre utilis√© !")